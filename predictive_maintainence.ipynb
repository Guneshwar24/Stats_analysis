{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4YNMzT-_mRS"
   },
   "source": [
    "# **Dataset Description** üìÉ\n",
    "Dataset source: [UCI](https://archive.ics.uci.edu/dataset/601/ai4i+2020+predictive+maintenance+dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twEuUsYLehPp"
   },
   "source": [
    "<h3>About Dataset üìÅ</h3> \n",
    "\n",
    "<img src = \"https://cdn-icons-png.flaticon.com/512/2162/2162407.png\" width = 100, height = 100>\n",
    "\n",
    "This synthetic dataset is modeled after an existing ***milling machine*** and consists of **10,000 data points** stored as rows with **14 features** in columns:\n",
    "\n",
    "\n",
    "\n",
    "1. `UID`: unique identifier ranging from 1 to 10000.\n",
    "2. `product ID`: consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial number.\n",
    "3. `type`: just the product type L, M or H from column 2.\n",
    "4. `air temperature` [K]: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K.\n",
    "5. `process temperature` [K]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.\n",
    "\n",
    "for more information about random walk process used in `air temperature`, and `process temperature`, check [this link](https://machinelearningmastery.com/gentle-introduction-random-walk-times-series-forecasting-python/).\n",
    "\n",
    "6. `rotational speed` [rpm]: calculated from a power of 2860 W, overlaid with a normally distributed noise.\n",
    "7. `torque` [Nm]: torque values are normally distributed around 40 Nm with a SD = 10 Nm and no negative values.\n",
    "8.` tool wear` [min]: (breakdown and gradual failure of a cutting tool due to regular operation) The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process.\n",
    "9. a '`machine failure`' label that indicates, whether the machine has failed in this particular datapoint for any of the following failure modes are true.\n",
    "The machine failure consists of five independent failure modes:\n",
    "\n",
    "\n",
    "> **Tool wear failure** (`TWF`): the tool will be replaced of fail at a randomly selected tool wear time between 200 - 240 mins (120 times in our dataset). At this point in time, the tool is replaced 69 times, and fails 51 times (randomly assigned).\n",
    "\n",
    "> **Heat dissipation failure** (`HDF`): heat dissipation causes a process failure, if the difference between air and process temperature is below 8.6 K and the tools rotational speed is below 1380 rpm. This is the case for 115 data points.\n",
    "\n",
    "> **Power failure** (`PWF`): the product of torque and rotational speed (in rad/s) equals the power required for the process. If this power is below 3500 W or above 9000 W, the process fails, which is the case 95 times in our dataset.\n",
    "\n",
    "> **Overstrain failure** (`OSF`): if the product of tool wear and torque exceeds 11,000 minNm for the L product variant (12,000 M, 13,000 H), the process fails due to overstrain. This is true for 98 datapoints.\n",
    "\n",
    "> **Random failures** (`RNF`): each process has a chance of 0,1 % to fail regardless of its process parameters. This is the case for only 5 datapoints, less than could be expected for 10,000 datapoints in our dataset.\n",
    "\n",
    "\n",
    "\n",
    "If at least one of the above failure modes is true, the process fails and the 'machine failure' label is set to 1. It is therefore not transparent to the machine learning method, which of the failure modes has caused the process to fail.\n",
    "\n",
    "This dataset is part of the following publication:\n",
    "S. Matzka, \"Explainable Artificial Intelligence for Predictive Maintenance Applications,\" 2020 Third International Conference on Artificial Intelligence for Industries (AI4I), 2020, pp. 69-74:.\n",
    "\n",
    "**Acronyms:**\n",
    "\n",
    "* [K]: kelvin\n",
    "* [rpm]: revolutions per minute\n",
    "* [Nm]: newton-meter\n",
    "* [min]: minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtvH3JdeA4QL"
   },
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeVD-rEAgmW1"
   },
   "source": [
    "# **Getting started** ‚è≠\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoF88QuPqPCO"
   },
   "source": [
    "## **Install and import the required libraries** ‚è¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T11:57:12.517859Z",
     "iopub.status.busy": "2024-11-04T11:57:12.517320Z"
    },
    "id": "-ZzHlD-TI0kB",
    "outputId": "c5114b6f-599b-4a93-b8d7-87a8bf00bff4",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping pandas-profiling as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikit-learn 1.5.2 requires joblib>=1.2.0, but you have joblib 1.1.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\gunes\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# install pandas profiling library\n",
    "!pip uninstall -y pandas-profiling --quiet\n",
    "!pip install -U pandas-profiling --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2GR-koXOiLE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "import ydata_profiling as pdpf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dyyv7njuqgv8"
   },
   "source": [
    "## **Load the dataset** üíΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDliVZS_HSo3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset_path = '/kaggle/input/predictive-maintenance-dataset-ai4i-2020/ai4i2020.csv'\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "288drgg5OxYG",
    "outputId": "d56530da-99cb-423e-bec3-9cc19bfcc000",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# total number of rows and columns\n",
    "print(f\"Number of rows: {df.shape[0]}, Number of columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S00HzhhTY1jb",
    "outputId": "15b38af8-4982-422f-b698-6931c55beaab",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rm0pn_q2DrLb"
   },
   "source": [
    "# **Data Preparation** ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ5G8wd0NTBK"
   },
   "source": [
    "## **Exploratory data analysis** üîç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SgwrMCiZLPq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# rename dataset columns\n",
    "df.rename(columns = {'Air temperature [K]':'Air temperature',\n",
    "                     'Process temperature [K]':'Process temperature',\n",
    "                     'Rotational speed [rpm]':'Rotational speed',\n",
    "                     'Torque [Nm]':'Torque',\n",
    "                     'Tool wear [min]':'Tool wear'},\n",
    "          inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cy4SMgP8cGeA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# drop UDI and Product ID columns\n",
    "df.drop(['Product ID', 'UDI'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJfR9iXwZwjz",
    "outputId": "d722e67c-7207-4b4b-9015-f48e7267c253",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4VU00Ppice8",
    "outputId": "91f34cb9-f541-4d75-f09a-46f7b8505127",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.info() # there are no null values, as it turns out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9j7c3FWvzd9l",
    "outputId": "572ed4cd-42cc-4a3b-ef3c-4a77bae07526",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# overall descriptive information on numerical attributes\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "df_numeric.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iW6pkCL8zvjl",
    "outputId": "a863541f-7476-4a01-94af-17e22b3b42c7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# overall descriptive information on categorical attributes\n",
    "df_categorical = df.select_dtypes(include=[np.object_])\n",
    "df_categorical.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6MQgJluramF"
   },
   "source": [
    "Plot the distribution for each attribute, We can see that the data is imbalanced (Type, Machine failure, TWF, HDF, PWF, OSF, RNF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oLwNunVW5YM",
    "outputId": "fe217bc9-7d85-413d-ce77-6ea3deb59585",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 4, figsize=(25, 20))\n",
    "\n",
    "for i, col in enumerate(df.columns):\n",
    "    sns.histplot(df[col], ax=ax[i//4][i%4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6MUdCj9texD",
    "outputId": "8334d0fc-006b-4ca2-a1b5-8aaea25d0617",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_failures = df.loc[:, ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']]\n",
    "\n",
    "# Calculate the sum of the values in each row\n",
    "rows_sum = df_failures.sum(axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.countplot(x=rows_sum, ax=ax)\n",
    "for patch in ax.patches:\n",
    "    ax.annotate(str(patch.get_height()), (patch.get_x() + patch.get_width()/2, patch.get_height()), ha='center', va='bottom')\n",
    "ax.set_title('Number of failure types per record')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdkG1hY8KxgL"
   },
   "source": [
    "As shown above, 24 records contain more than one type of failure, but their count is very small compared to the entire data set, so we will combine the failure types into one feature. The individual failure types are then dropped.\n",
    "\n",
    "> No failure = 0, TWF = HDF = PWF = OSF = RNF = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eS8_hqwu6F2b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['Machine failure'] = 0\n",
    "\n",
    "df.loc[df['TWF'] == 1, 'Machine failure'] = 1\n",
    "df.loc[df['HDF'] == 1, 'Machine failure'] = 1\n",
    "df.loc[df['PWF'] == 1, 'Machine failure'] = 1\n",
    "df.loc[df['OSF'] == 1, 'Machine failure'] = 1\n",
    "df.loc[df['RNF'] == 1, 'Machine failure'] = 1\n",
    "\n",
    "# drop individual failure types\n",
    "df.drop(['TWF', 'HDF', 'PWF', 'OSF', 'RNF'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1lZ3HCA4pPE",
    "outputId": "35aa44ac-e8be-4738-cc27-15729897a526",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "failure_types = df.loc[:, ['Machine failure']]\n",
    "\n",
    "rows_sum = failure_types.sum(axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.countplot(x=rows_sum, ax=ax)\n",
    "for patch in ax.patches:\n",
    "    ax.annotate(str(patch.get_height()), (patch.get_x() + patch.get_width()/2, patch.get_height()), ha='center', va='bottom')\n",
    "    ax.set_title('Count of different failure types')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZXWuQ_p-hD_"
   },
   "source": [
    "We can derive a new attribute using this formula:\n",
    "\n",
    "$Power = Torque \\times Rotational \\ speed$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lnd1T9AVAqYd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['Power'] = df[['Rotational speed', 'Torque']].product(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbOvvNDsT08u",
    "outputId": "8dcec398-f795-4ad2-bd71-409a9cb772d4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot the histogram of Power attribute\n",
    "sns.histplot(df['Power'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGZ8sMrVZ614"
   },
   "source": [
    "## **Data type conversion** ‚õìÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6qRlvurXTk7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert Type attribute into numbers, such that L = 0, M = 1, and H = 2\n",
    "df['Type'].replace('L', 0, inplace=True)\n",
    "df['Type'].replace('M', 1, inplace=True)\n",
    "df['Type'].replace('H', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3oym2AbyOKO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# turn all columns into float for easier processing later\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4arFIakyoPt",
    "outputId": "4d47cb9f-f994-43cf-989a-5c898b31dbc6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# view columns data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AoVjBkSasvf"
   },
   "source": [
    "## **Handling outliers**‚ùó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfPPjmwxsahc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# List of columns to exclude from normalization and winsorization\n",
    "excluded_columns = ['Type', 'Machine failure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoLXLzB1aE9l"
   },
   "source": [
    "Calculate and handle the outliers for each attribute using IQR and Winsorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6FYmVxrni-A",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in excluded_columns:\n",
    "        # calculate the IQR (interquartile range)\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = df[(df[col] <= (Q1 - 1.5 * IQR)) | (df[col] >= (Q3 + 1.5 * IQR))]\n",
    "        if not outliers.empty:\n",
    "          #df.loc[outliers.index, col] = winsorize(outliers[col], limits=[0.08, 0.08])\n",
    "          df.drop(outliers.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z-ksDlMlQcP"
   },
   "source": [
    "Density-Based Anomaly Detection (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mU5-__wfcX5n",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# create the LOF model\n",
    "model = LocalOutlierFactor(n_neighbors=5)\n",
    "\n",
    "# use the model to predict the outlier scores for each row\n",
    "scores = model.fit_predict(df)\n",
    "\n",
    "# identify the outlier rows (those with a negative score) and remove them\n",
    "outliers = df[scores == -1]\n",
    "if not outliers.empty:\n",
    "    df.drop(outliers.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3eM4ZZxv11R",
    "outputId": "1ef61e19-6ad6-4bd5-8766-04c83f9ffedd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.shape # after removing the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PriYkty1aUqw"
   },
   "source": [
    "## **Transformation** ‚õèÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYPHhQffW9Nm"
   },
   "source": [
    "Normalize the attributes using z-score\n",
    "\n",
    "$z = \\frac{x - \\mu} {\\sigma}$, $\\mu:$ Mean, $œÉ:$ Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoaywCrlU7qf",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Iterate over the columns in the dataframe\n",
    "for col in df.columns:\n",
    "      if col not in excluded_columns:\n",
    "        # Normalize the values in the column\n",
    "        df[col] = zscore(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5W-YYtHo8lc"
   },
   "source": [
    "## **More visualizations** üìä "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJduOWWYB9_D"
   },
   "source": [
    "Box and Whisker Plots for each attribute compared with Machine failure (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTBHo5kU8QqY",
    "outputId": "de61777a-3a3d-46a5-9103-bb48e57af790",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(20, 10))\n",
    "for i, col in enumerate(df.columns):\n",
    "    sns.boxplot(x=\"Machine failure\", y=col, data=df, ax=ax[i//4][i%4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-XQT4IUZEa9"
   },
   "source": [
    "Box and Whisker Plots for each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50yxlNhoQJnZ",
    "outputId": "edc8c12a-cf17-4cea-d9ce-12c30fd7b870",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_columns = [col for col in df.columns if col not in excluded_columns]\n",
    "df[plot_columns].plot(kind='box', figsize=(12, 6), title='Box and Whisker Plots', ylabel='Value', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHTRY4dH4vLQ"
   },
   "source": [
    "Finding the correlation between the attributes with threshold = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KbAfaQXqHVZ",
    "outputId": "e3580414-8ff9-4fee-863b-f609e421cd9f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# There are strongly correlated features\n",
    "threshold = 0.3\n",
    "correlation = df.corr()\n",
    "matrix = correlation.where((abs(correlation) >= threshold)).isna()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), cmap=\"coolwarm\", annot=True, mask=matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbT_KnYT59sz"
   },
   "source": [
    "A scatter plot matrix to display the relationships between attributes in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bs2JHo2KG8Uv",
    "outputId": "98d1d90d-b87d-4a87-e2ed-8ebfc9d8e442",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df.sample(frac=0.05), hue='Machine failure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4yJ5oDhXAsa"
   },
   "source": [
    "Parallel coordinate plot (multi-dimensional view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhuJyGrLPKAG",
    "outputId": "f9d67947-fc0b-4a73-f726-01ba1d2af3a4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = df.sort_values(by=['Machine failure'], ascending=False).head(300)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "pd.plotting.parallel_coordinates(sample, 'Machine failure', color=('#3D5656', '#68B984', '#FED049'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-lYmJ_t57hI"
   },
   "source": [
    "Generate a profile report that includes (outliers, missing values, distributions, etc.) using [pandas-profiling](https://pandas-profiling.ydata.ai/docs/master/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbpysvYYpqB9",
    "outputId": "b075d8d3-71e0-4fc5-8330-5cc07d773e0a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_profile = pdpf.ProfileReport(df, dark_mode=True)\n",
    "df_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNu4_iyFPfue"
   },
   "source": [
    "# **Descriptive analytics** üìù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCXyw7swPyzF"
   },
   "source": [
    "## **Clustering** üß©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRVDU40BsTVY",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# features to use for clustering\n",
    "X = df[[\"Air temperature\", \"Process temperature\", \"Rotational speed\", \"Torque\", \"Tool wear\", \"Power\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfCOntLSZfn9"
   },
   "source": [
    "* Partitional Clustering, **K-means algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgcRNT75ttmQ"
   },
   "source": [
    "Elbow method to determine the optimal number (k) of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swDjU_KElK0W",
    "outputId": "52c1ad01-6453-4676-ddca-54b008c4e333",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# K-means clustering\n",
    "model = KMeans()\n",
    "\n",
    "visualizer = KElbowVisualizer(model, k=(2,10)) # it turns out that k = 4 is the optimal number of clusters \n",
    "\n",
    "visualizer.fit(X)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1cTv_kmuUwI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# K-means clustering\n",
    "kmeans = KMeans(init=\"random\",  n_clusters=4,\n",
    "                n_init=10, max_iter=300, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "df[\"kmeans_cluster\"] = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0sr2FN0ulfe"
   },
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12CK2ODhagml",
    "outputId": "201ffa95-7a56-496b-8f8a-244b594bf76b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# create a pairplot of the data, colored by cluster label\n",
    "sns.pairplot(df.sample(frac=0.05), hue=\"kmeans_cluster\", vars=[\"Air temperature\", \"Process temperature\", \"Rotational speed\", \"Torque\", \"Tool wear\", \"Power\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG6zAEDS2OUZ"
   },
   "source": [
    "Silhouette coefficient for k-means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuhUtw-mxUif",
    "outputId": "e38905e8-7198-49d5-c652-6ac9b892246a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# calculate the silhouette coefficient\n",
    "score = silhouette_score(X, kmeans.predict(X))\n",
    "\n",
    "print(f\"Silhouette Coefficient: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGNWlAWj34nu"
   },
   "source": [
    "* Hierarchical clustering, **Agglomerative**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OL4VcNUtNIBn",
    "outputId": "9d1f0ed9-5a85-4f2a-e244-848d839ba9ab",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "# plot dendogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Predictive Maintenance Dendrogram\")\n",
    "\n",
    "# Selecting Annual Income and Spending Scores by index\n",
    "clusters = shc.linkage(X, method='ward', metric=\"euclidean\")\n",
    "shc.dendrogram(Z=clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PeQuQ8na6xh",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Hierarchical clustering\n",
    "model = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "model.fit(X)\n",
    "df[\"hierarchical_cluster\"] = model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XC3JV1fu4WeA"
   },
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHD6yWhQ4Rzn",
    "outputId": "1f287fba-cc8e-405b-8803-c9cfcb44b98b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# create a pairplot of the data, colored by cluster label\n",
    "sns.pairplot(df.sample(frac=0.05), hue=\"hierarchical_cluster\", vars=[\"Air temperature\", \"Process temperature\", \"Rotational speed\", \"Torque\", \"Tool wear\", \"Power\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0f_Offe43uk"
   },
   "source": [
    "Silhouette coefficient for Agglomerative clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVakZU9543ul",
    "outputId": "7b73f137-dcae-477a-856a-61965f2cf351",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# calculate the silhouette coefficient\n",
    "score = silhouette_score(X, df[\"hierarchical_cluster\"])\n",
    "\n",
    "print(f\"Silhouette Coefficient: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zog7zMtI_Ry"
   },
   "source": [
    "* Density-based clustering, **DBSACN**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-d21WgxAIijB"
   },
   "source": [
    "Determining EPS and MinPts for DBSACN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxnCAc6nH9kU",
    "outputId": "478f8c14-03dc-4e40-e8f2-e6c32d0ab1f4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "k = 5\n",
    "\n",
    "# create the nearest neighbors model\n",
    "nn = NearestNeighbors(n_neighbors=k)\n",
    "nn.fit(X)\n",
    "\n",
    "# get the distances and indices of the kth nearest neighbors for each point\n",
    "distances, indices = nn.kneighbors(X)\n",
    "\n",
    "# get the kth nearest neighbor distances for each point\n",
    "kth_distances = distances[:, k-1]\n",
    "\n",
    "# sort the kth nearest neighbor distances\n",
    "kth_distances_sorted = np.sort(kth_distances)\n",
    "\n",
    "plt.plot(kth_distances_sorted)\n",
    "plt.xlabel('Point Index')\n",
    "plt.ylabel('5-th Nearest Neighbor Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCZcg2oWAT5U",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# create a DBSCAN model\n",
    "model = DBSCAN(eps=0.7, min_samples=5)\n",
    "model.fit(X)\n",
    "\n",
    "# obtain the cluster labels\n",
    "df['dbscan_cluster'] = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWAfyLcTBQvI",
    "outputId": "f1fc8546-cc69-44b0-bd1c-8d120825d149",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# calculate the silhouette coefficient\n",
    "score = silhouette_score(X, df[\"dbscan_cluster\"])\n",
    "\n",
    "print(f\"Silhouette Coefficient: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tT-b_cIJ1vJ"
   },
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kO6BjrVAwdo",
    "outputId": "ea80736e-3279-4059-a9c0-c1fa3beefc42",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# create a pairplot of the data, colored by cluster label\n",
    "sns.pairplot(df.sample(frac=0.05), hue=\"dbscan_cluster\", palette=\"vlag\", vars=[\"Air temperature\", \"Process temperature\", \"Rotational speed\", \"Torque\", \"Tool wear\", \"Power\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vD0fY4tRzTGd"
   },
   "source": [
    "# **Modeling** üß™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWUvtkNFAiEH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "model_performance = pd.DataFrame(columns=['Accuracy', 'Precision',\n",
    "                                          'Recall', 'F1-Score', 'Training time',\n",
    "                                          'Prediction time'])\n",
    "\n",
    "def log_scores(model_name, y_test, y_predictions):\n",
    "    accuracy = accuracy_score(y_test, y_predictions)\n",
    "    precision = precision_score(y_test, y_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, y_predictions, average='weighted')\n",
    "    precision = precision_score(y_test, y_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, y_predictions, average='weighted')\n",
    "\n",
    "    # save the scores in model_performance dataframe\n",
    "    model_performance.loc[model_name] = [accuracy, precision, recall, f1,\n",
    "                                       end_train-start, end_predict-end_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6Nljxy6HMmc"
   },
   "source": [
    "## **Data splitting and sampling** üßÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIje_AJpc15c",
    "outputId": "52d42171-2087-4905-e794-c2637a99b0a9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-bB_yXvI77_"
   },
   "source": [
    "Split the dataset (70% train : 30% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sflst93hIERl",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop([\"Machine failure\", \"kmeans_cluster\", \"hierarchical_cluster\", \"dbscan_cluster\"], axis=1)\n",
    "y = df[\"Machine failure\"]\n",
    "\n",
    "# Split the data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 0,\n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8amYq3J6F1K9"
   },
   "source": [
    "Because the data is imbalanced, we oversample the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = SVMSMOTE(random_state = 42)\n",
    "#oversample = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhH3vPPKVvEc"
   },
   "source": [
    "Training set after oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4y8klR3zVpxi",
    "outputId": "f25b37eb-1720-47a8-f213-cef597219c29",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFiPHBsDwbPj"
   },
   "source": [
    "## **Decision Tree Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0yzFhvsCMed"
   },
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aiEe0Iy0xQp0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "start = time.time()\n",
    "model = DecisionTreeClassifier(max_depth = 8).fit(X_train, y_train)\n",
    "end_train = time.time()\n",
    "y_predictions = model.predict(X_test)\n",
    "end_predict = time.time()\n",
    "\n",
    "# evaluate the model\n",
    "log_scores(\"Decision Tree\", y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPN_5vnbWRd3"
   },
   "source": [
    "Model evaluation for each Machine failure class:\n",
    "\n",
    "0. No failure\n",
    "1. Machine failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uw1RWt9kDc68",
    "outputId": "0f4131d9-e1bf-4367-b6f3-21bfce5b7476",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Decision Tree\\n\" + classification_report(y_test, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzWHmvYiDZLm",
    "outputId": "9b802b5a-1e47-4d1e-c8c0-4f6f564acd89",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5)\n",
    "\n",
    "# plot the learning curve\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), label='Training score')\n",
    "plt.plot(train_sizes, test_scores .mean(axis=1), label='Testing score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvI-NP2LZmc-"
   },
   "source": [
    "Confusion matrix of Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PXUpZd4YvsD",
    "outputId": "bb94266c-b247-422c-a2d3-164bb1b3a8c0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predictions, cmap=plt.cm.YlGnBu)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_rm0yMspr32",
    "outputId": "94988cff-b36d-4514-ab3c-bf20f94cb822",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "data = tree.export_graphviz(model,\n",
    "                            feature_names=X.columns,  \n",
    "                            class_names=['No failure','TWF','HDF','PWF','OSF','RNF'],\n",
    "                            filled=True)\n",
    "\n",
    "# draw graph\n",
    "graph = graphviz.Source(data, format=\"png\") \n",
    "graph.render('nodes', view=False)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFyx-cms5TXk",
    "outputId": "e81c9c93-9493-4ab1-a42e-a6c03e451d16",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "rules = export_text(model)\n",
    "\n",
    "# print the rules\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdEevcVJocxR"
   },
   "source": [
    "## **k-NN (K-nearest neighbors) Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_B_xlmgocxS",
    "outputId": "83294afa-d20d-47e9-8b11-cef1b40a7430",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create the model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# define the parameter grid\n",
    "param_grid = {'n_neighbors': range(2, 20)}\n",
    "\n",
    "# create the grid search object\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best parameters\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azpRxZn1ocxS"
   },
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wO3HTQ2hocxT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = KNeighborsClassifier(n_neighbors=2).fit(X_train, y_train)\n",
    "end_train = time.time()\n",
    "y_predictions = model.predict(X_test) # predictions from the testset\n",
    "end_predict = time.time()\n",
    "\n",
    "# evaluate the model\n",
    "log_scores(\"k-NN\", y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsErsIsxocxT"
   },
   "source": [
    "Model evaluation for each Machine failure class:\n",
    "\n",
    "0. No failure\n",
    "1. Machine failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeC6aS61ocxT",
    "outputId": "0e1a96bc-4e3b-4a62-8327-98038d054757",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"k-NN Model\\n\" + classification_report(y_test, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLKpuuqNocxU",
    "outputId": "f7233e7e-9aa1-43d7-91d0-45e4a1467dfe",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5)\n",
    "\n",
    "# plot the learning curve\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), label='Training score')\n",
    "plt.plot(train_sizes, test_scores .mean(axis=1), label='Testing score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9gCKkSJocxU"
   },
   "source": [
    "Confusion matrix of k-NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Isu0lcpgocxU",
    "outputId": "61a33e7f-311d-422f-8a10-8ee7a363d5d3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predictions, cmap=plt.cm.YlGnBu)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1hdpPU3c_P7"
   },
   "source": [
    "## **Random Forest Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRn2uYgoc_P9"
   },
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtHk-xS3c_P9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start = time.time()\n",
    "model = RandomForestClassifier(n_estimators=100, n_jobs=-1,\n",
    "                               random_state=0, bootstrap=True).fit(X_train, y_train)\n",
    "end_train = time.time()\n",
    "y_predictions = model.predict(X_test)\n",
    "end_predict = time.time()\n",
    "\n",
    "# evaluate the model\n",
    "log_scores(\"Random Forest\", y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLPX8ahFc_P-"
   },
   "source": [
    "Model evaluation for each Machine failure class:\n",
    "\n",
    "0. No failure\n",
    "1. Machine failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLYWJDjjc_P_",
    "outputId": "bc70543f-5e02-4841-9f87-6697ef7969bc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Random Forest Model\\n\" + classification_report(y_test, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlpStXhtc_QA",
    "outputId": "d93ccee8-c2ef-4377-9731-79c25e46a0b2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5)\n",
    "\n",
    "# plot the learning curve\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), label='Training score')\n",
    "plt.plot(train_sizes, test_scores .mean(axis=1), label='Testing score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HhJBJK7c_QA"
   },
   "source": [
    "Confusion matrix of Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHteGblcc_QB",
    "outputId": "46c3eb1c-620c-401e-a6ce-ccf622feb510",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predictions, cmap=plt.cm.YlGnBu)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_DmCDsLogK7"
   },
   "source": [
    "## **Gradient Boosting Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aEM4KVbogK-"
   },
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXvWzgVCogK-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "start = time.time()\n",
    "model = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "end_train = time.time()\n",
    "y_predictions = model.predict(X_test)\n",
    "end_predict = time.time()\n",
    "\n",
    "# evaluate the model\n",
    "log_scores(\"Gradient Boosting\", y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "023apuBVogK_"
   },
   "source": [
    "Model evaluation for each Machine failure class:\n",
    "\n",
    "0. No failure\n",
    "1. Machine failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyVlRisrogLA",
    "outputId": "a6cf98a4-cfdc-4b3f-badf-7eb063f7c51b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Gradient Boosting\\n\" + classification_report(y_test, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUgTGivKogLA",
    "outputId": "a0ff5616-4d45-48f0-b0e4-1cf5659c8a55",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5)\n",
    "\n",
    "# plot the learning curve\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), label='Training score')\n",
    "plt.plot(train_sizes, test_scores .mean(axis=1), label='Testing score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxpaeZuaogLB"
   },
   "source": [
    "Confusion matrix of Gradient Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNKyGAQ7ogLB",
    "outputId": "0d390be0-22da-4c8a-d8cc-8d7a8b761609",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predictions, cmap=plt.cm.YlGnBu)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-AFi1wgEBH6"
   },
   "source": [
    "## **Gaussian Naive Bayes Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQ38G-L3EBH7"
   },
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMHvs3WtEHlC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "start = time.time()\n",
    "model = GaussianNB().fit(X_train, y_train)\n",
    "end_train = time.time()\n",
    "y_predictions = model.predict(X_test)\n",
    "end_predict = time.time()\n",
    "\n",
    "# evaluate the model\n",
    "log_scores(\"Gaussian Naive Bayes\", y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDVN_nsiEBH7"
   },
   "source": [
    "Model evaluation for each Machine failure class:\n",
    "\n",
    "0. No failure\n",
    "1. Machine failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHHPlXBEEBH7",
    "outputId": "1747ccbb-7df3-4473-bc00-e96c176fe743",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Gaussian Naive Bayes\\n\" + classification_report(y_test, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EJwOzWBEBH7",
    "outputId": "17f448e4-eff8-4ff2-8b0d-7790c1e118ab",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5)\n",
    "\n",
    "# plot the learning curve\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), label='Training score')\n",
    "plt.plot(train_sizes, test_scores .mean(axis=1), label='Testing score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4dk3M9wEBH7"
   },
   "source": [
    "Confusion matrix of Gaussian Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vku12-IfEBH7",
    "outputId": "b7757051-4245-4215-a742-20d09e2371b6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predictions, cmap=plt.cm.YlGnBu)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MLP (Multi-layer Perceptron) Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "start = time.time()\n",
    "model = MLPClassifier(random_state=1, max_iter=600, learning_rate=\"invscaling\").fit(X_train, y_train)\n",
    "end_train = time.time()\n",
    "y_predictions = model.predict(X_test)\n",
    "end_predict = time.time()\n",
    "\n",
    "# evaluate the model\n",
    "log_scores(\"Multi-layer Perceptron\", y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation for each Machine failure class:\n",
    "\n",
    "0. No failure\n",
    "1. Machine failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Multi-layer Perceptron\\n\" + classification_report(y_test, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5)\n",
    "\n",
    "# plot the learning curve\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), label='Training score')\n",
    "plt.plot(train_sizes, test_scores .mean(axis=1), label='Testing score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(model.loss_curve_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix of Multi-layer Perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predictions, cmap=plt.cm.YlGnBu)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEXgx0gB1xHi"
   },
   "source": [
    "# **Evaluation** üé≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXEBw6ZTCyYE",
    "outputId": "60b05f3d-7ac0-4e4f-adb6-f032bc2bb6bc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeHl-tUQFVFz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# build the Decision Tree classifier\n",
    "model = DecisionTreeClassifier(max_depth = 8).fit(X_train, y_train)\n",
    "\n",
    "# save the model\n",
    "pickle.dump(model, open('finalized_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HR_HeXzP2PBU"
   },
   "source": [
    "# **Deployment** üì§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G5HwGyTCotj"
   },
   "source": [
    "Demo the predictive machine learning model using [Gradio](https://gradio.app/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKB44oks2nI7",
    "outputId": "aa6a2d44-a6a5-4737-ae05-a94ccd8b2c56",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install gradio --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kb26k5sPLSCb"
   },
   "source": [
    "Load the saved model and the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XZ2SeYVG51g",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('/kaggle/working//finalized_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeLJBWNbK1qG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dataset_path)\n",
    "\n",
    "# rename dataset columns\n",
    "dataset.rename(columns = {'Air temperature [K]':'Air temperature',\n",
    "                     'Process temperature [K]':'Process temperature',\n",
    "                     'Rotational speed [rpm]':'Rotational speed',\n",
    "                     'Torque [Nm]':'Torque',\n",
    "                     'Tool wear [min]':'Tool wear'},\n",
    "          inplace = True)\n",
    "dataset['Power'] = dataset[['Rotational speed', 'Torque']].product(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sII58Q3Lngm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# normalize the feature using z-score normalization\n",
    "def z_score(feature, value):\n",
    "    mean = np.mean(dataset[feature])\n",
    "    std = np.std(dataset[feature])\n",
    "    return (float(value) - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPrlXx4_2qka",
    "outputId": "76fc369d-07d8-4df8-f975-e2bd093d25f8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def predict(air_temperature, process_temperature, rotational_speed, torque, tool_wear, type):\n",
    "    # normalize the inputs\n",
    "    air_temperature = z_score('Air temperature', air_temperature)\n",
    "    process_temperature = z_score('Process temperature', process_temperature)\n",
    "    rotational_speed = z_score('Rotational speed', rotational_speed)\n",
    "    torque = z_score('Torque', torque)\n",
    "    tool_wear = z_score('Tool wear', tool_wear)\n",
    "    power = z_score('Power', torque * rotational_speed)\n",
    "\n",
    "    mapping = {'L': 0, 'M': 1, 'H': 2}\n",
    "    temp = [{'Type':mapping[type], 'Air temperature':air_temperature,\n",
    "             'Process temperature':process_temperature, 'Rotational speed':rotational_speed,\n",
    "             'Torque':torque, 'Tool wear':tool_wear, 'Power':power}]\n",
    "\n",
    "    input_data = pd.DataFrame(temp) \n",
    "    prediction = model.predict_proba(input_data)\n",
    "\n",
    "    classes = [\"No failure\", \"Machine failure\"]\n",
    "    prediction_dict = dict\n",
    "    for record in prediction:\n",
    "        prediction_dict = {classes[i] : record[i] for i in range(2)}\n",
    "    \n",
    "    maintenance = \"No action required\"\n",
    "    if max(prediction_dict, key=prediction_dict.get) != \"No failure\":\n",
    "        maintenance = \"Need maintenance\"\n",
    "\n",
    "    return prediction_dict, maintenance\n",
    "\n",
    "# create the user interface (inputs and outputs)\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[gr.Slider(100, 350, label=\"Air temperature\"),\n",
    "            gr.Slider(100, 350, label=\"Process temperature\"),\n",
    "            gr.Number(label=\"Rotational speed\"),\n",
    "            gr.Number(label=\"Torque\"),\n",
    "            gr.Number(label=\"Tool wear\"),\n",
    "            gr.Radio([\"L\", \"M\", \"H\"], label=\"Type\")],\n",
    "    outputs=[gr.Label(num_top_classes=2, label=\"Result\"), gr.components.Textbox(label=\"Action\")]\n",
    ")\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2609801,
     "sourceId": 4458097,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30369,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
